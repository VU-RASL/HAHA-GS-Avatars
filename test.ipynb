{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/envs/textured-avatar/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "from enum import Enum\n",
    "\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.general import instantiate_from_config\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from utils.data import dict2device\n",
    "import numpy as np\n",
    "import json\n",
    "import smplx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parser(**parser_kwargs):\n",
    "    parser = argparse.ArgumentParser(**parser_kwargs)\n",
    "    parser.add_argument(\n",
    "        \"-b\",\n",
    "        \"--base\",\n",
    "        nargs=\"*\",\n",
    "        metavar=\"base_config.yaml\",\n",
    "        help=\"Paths to base configs. Loaded from left-to-right. \"\n",
    "             \"Parameters can be overwritten or added with command-line options of the form `--key value`.\",\n",
    "        default=list(),\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-t\",\n",
    "        \"--test_mode\",\n",
    "        action='store_true',\n",
    "        help=\"Only evaluate metrics from the checkpoint\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-p\",\n",
    "        \"--pretrained\",\n",
    "        type=str,\n",
    "        const=True,\n",
    "        default=None,\n",
    "        nargs=\"?\",\n",
    "        help=\"Load pretrained weights from the checkpoint\",\n",
    "    )\n",
    "    return parser\n",
    "\n",
    "def generate_path_to_logs(config, opt, sequence_name):\n",
    "    experiment_name = opt.base[0].split('/')[-1].split('.yaml')[0]\n",
    "    time = datetime.datetime.now()\n",
    "    run_name = sequence_name + time.strftime(f\"-%Y_%m-%d_%H-%M\")\n",
    "    log_dir = os.path.join(config.logdir, experiment_name, run_name)\n",
    "    return log_dir\n",
    "\n",
    "\n",
    "def create_test_datasets(config):\n",
    "    test_dataset = instantiate_from_config(config.test_dataloader)\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config.val_dataloader.batch_size,\n",
    "        num_workers=config.val_dataloader.num_workers,\n",
    "        shuffle=False,\n",
    "        pin_memory=False,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    print(\"Test samples:\", len(test_dataloader))\n",
    "    return test_dataset, test_dataloader\n",
    "\n",
    "\n",
    "def create_train_val_datasets(config):\n",
    "    train_dataset = instantiate_from_config(config.train_dataloader)\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.train_dataloader.batch_size,\n",
    "        num_workers=config.train_dataloader.num_workers,\n",
    "        shuffle=True,\n",
    "        pin_memory=False,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    print(\"Training samples:\", len(train_dataloader))\n",
    "\n",
    "    test_dataset = instantiate_from_config(config.val_dataloader)\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config.val_dataloader.batch_size,\n",
    "        num_workers=config.val_dataloader.num_workers,\n",
    "        shuffle=False,\n",
    "        pin_memory=False,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    print(\"Validation samples:\", len(test_dataloader))\n",
    "\n",
    "    return train_dataset, train_dataloader, test_dataloader\n",
    "\n",
    "\n",
    "def setup_tensorboard_logger(runner, config, opt, sequence_name):\n",
    "    log_dir = generate_path_to_logs(config, opt, sequence_name)\n",
    "    if opt.test_mode:\n",
    "        log_dir += '-test'\n",
    "    os.makedirs(log_dir, exist_ok=False)\n",
    "    runner.logger = SummaryWriter(log_dir)\n",
    "\n",
    "\n",
    "def setup_callbacks(runner, config):\n",
    "    callbacks = []\n",
    "    for callback_config in config.callbacks.values():\n",
    "        callbacks.append(instantiate_from_config(callback_config))\n",
    "    runner.set_callbacks(callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda/envs/textured-avatar/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/user/miniconda/envs/textured-avatar/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/user/miniconda/envs/textured-avatar/lib/python3.8/site-packages/lpips/weights/v0.1/vgg.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mounted/home/dresden/repositories/HAHA/runners/train_gaussians.py:205: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  self._gaussian_to_face = torch.nn.Parameter(torch.range(0, npoints - 1, dtype=torch.long, device=self.device),\n",
      "/home/user/miniconda/envs/textured-avatar/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.\n",
      "  _future_warning(\n",
      "/home/user/miniconda/envs/textured-avatar/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `StructuralSimilarityIndexMeasure` from `torchmetrics` was deprecated and will be removed in 2.0. Import `StructuralSimilarityIndexMeasure` from `torchmetrics.image` instead.\n",
      "  _future_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Gaussians: 13541\n",
      "Test samples: 14\n"
     ]
    }
   ],
   "source": [
    "parser = get_parser()\n",
    "\n",
    "# opt, unknown = parser.parse_known_args(['--base=./configs/gaussians_docker_male3.yaml', '--pretrained=./logs/gaussians_docker_male3/male-3-casual-2024_12-20_21-04/checkpoints/OPTIMIZE_OPACITY_10500.ckpt', '--test_model'])\n",
    "\n",
    "opt, unknown = parser.parse_known_args(['--base=./configs/gaussians_docker_male3.yaml', '--pretrained=./logs/gaussians_docker_male3/male-3-casual-2024_12-20_21-04/checkpoints/OPTIMIZE_OPACITY_10500.ckpt', '--test_model'])\n",
    "\n",
    "configs = [OmegaConf.load(cfg) for cfg in opt.base]\n",
    "cli = OmegaConf.from_dotlist(unknown)\n",
    "config = OmegaConf.merge(*configs, cli)\n",
    "\n",
    "runner = instantiate_from_config(config.runner)\n",
    "runner.to(runner.device)\n",
    "\n",
    "setup_callbacks(runner, config)\n",
    "runner.load_checkpoint(opt.pretrained)\n",
    "test_dataset, test_dataloader = create_test_datasets(config)\n",
    "setup_tensorboard_logger(runner, config, opt, test_dataset.sequence_name)\n",
    "runner.initialize_optimizable_pose(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.save_ply('./male3.ply',runner._xyz, runner._color, runner._opacity, runner._scaling,runner._rotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setTPoseAndZero(batch):\n",
    "    batch['smplx_params']['global_orient'][0] = torch.zeros(3)\n",
    "    batch['smplx_params']['transl'][0] = torch.zeros(3)\n",
    "    batch['smplx_params']['body_pose'][0] = torch.zeros([1,63])\n",
    "    batch['smplx_params']['left_hand_pose'][0] = torch.zeros([1,12])\n",
    "    batch['smplx_params']['right_hand_pose'][0] = torch.zeros([1,12])\n",
    "    batch['smplx_params']['jaw_pose'][0] = torch.zeros([1,3])\n",
    "    batch['smplx_params']['leye_pose'][0] = torch.zeros([1,3])\n",
    "    batch['smplx_params']['reye_pose'][0] = torch.zeros([1,3])\n",
    "    batch['smplx_params']['expression'][0] = torch.zeros([1,10])\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingStage(Enum):\n",
    "    INIT_TEXTURE = \"INIT_TEXTURE\"\n",
    "    OPTIMIZE_GAUSSIANS = \"OPTIMIZE_GAUSSIANS\"\n",
    "    FINETUNE_TEXTURE = \"FINETUNE_TEXTURE\"\n",
    "    OPTIMIZE_OPACITY = \"OPTIMIZE_OPACITY\"\n",
    "    FINETUNE_POSE = \"FINETUNE_POSE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(test_dataloader)\n",
    "batch = next(it)\n",
    "# batch = setTPoseAndZero(batch)\n",
    "# data_dict = dict2device(batch, \"cuda\")\n",
    "# output = runner.predict_smplx_vertices(batch, calc_gaussians=True)\n",
    "# runner._render_frame(data_dict, \"FINETUNE_POSE\")\n",
    "# for key in output.keys():\n",
    "    # output[key] = output[key][0,:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "print(batch[\"smplx_params\"][\"transl\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00000', '00001', '00002', '00003']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['pid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.save_ply('./male3.ply',runner._xyz, runner._color, runner._opacity, runner._scaling,runner._rotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = runner.predict_smplx_vertices(batch, calc_gaussians=True)\n",
    "# runner.save_ply('./male3-test.ply',runner._xyz, runner._color, runner._opacity, runner._scaling,runner._rotation)\n",
    "for key in output.keys():\n",
    "    output[key] = output[key][1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in output.keys():\n",
    "    print(k)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in output.keys():\n",
    "    print(k)\n",
    "runner.save_ply('./male3-test.ply',\n",
    "                output['gaussians_xyz'],\n",
    "                output['gaussians_colors'],\n",
    "                output['gaussians_opacity'],\n",
    "                output['gaussians_scales'],\n",
    "                output['gaussians_rotations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load(opt.pretrained)\n",
    "print(opt.pretrained)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['state_dict'] = runner.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = data['state_dict']\n",
    "for key in list(state_dict.keys()):\n",
    "    if key.startswith('_body_pose_dict'):\n",
    "        del state_dict[key]\n",
    "state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"lpips\")}\n",
    "# print(state_dict['_smplx_model.lbs_weights'].shape)\n",
    "# print(state_dict['_smplx_model.pose_mean'].shape)\n",
    "# for key in list(state_dict.keys()):\n",
    "#     print(key)\n",
    "# len(state_dict[\"_xyz\"])\n",
    "# state_dict = data\n",
    "for key in list(state_dict.keys()):\n",
    "    if key.startswith('_body_pose_dict'):\n",
    "        del state_dict[key]\n",
    "state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"lpips\")}\n",
    "state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"_xyz_gradient\")}\n",
    "state_dict['_faces'] = state_dict['_smplx_model.faces_tensor']\n",
    "# state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"_smplx\")}\n",
    "state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"_max\")}\n",
    "# print(state_dict['_smplx_model.lbs_weights'].shape)\n",
    "# print(state_dict['_smplx_model.pose_mean'].shape)\n",
    "for key,value in list(state_dict.items()):\n",
    "    print(f'{key}: {value.shape}')\n",
    "    # print(key)\n",
    "# len(state_dict[\"_xyz\"])\n",
    "data = state_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict['_smplx_model.faces_tensor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemapToUnity(smplx_path,unity_path, data):\n",
    "    # get canonical vertices, flat_hand_mean=True to align with unity default pose\n",
    "    smplx_model = smplx.create(smplx_path, model_type='smplx', gender='male', flat_hand_mean=True)\n",
    "    output = smplx_model(return_full_pose=True)\n",
    "    canonical_vertices = output.vertices.detach().cpu().numpy().squeeze()\n",
    "\n",
    "    # get unity vertices\n",
    "    with open(\"ExportedVertices.json\", \"r\") as f:\n",
    "        unity_data = json.load(f)\n",
    "    u = np.array(unity_data['vertices'])\n",
    "\n",
    "    tolerance = 5e-5\n",
    "    map = []\n",
    "    # create mapping of canonical -> unity \n",
    "    for i, canon_v in enumerate(canonical_vertices):\n",
    "        canon_v[0] *= -1\n",
    "        # print(f'({i},{canon_v})')\n",
    "        # Calculate distances between the current canonical vertex and all Unity vertices\n",
    "        distances = np.linalg.norm(u - canon_v, axis=1)\n",
    "        \n",
    "        # Find the closest Unity vertex\n",
    "        idx = np.argmin(distances)\n",
    "        \n",
    "        \n",
    "        # Check if the closest vertex is within the tolerance\n",
    "        if distances[idx] < tolerance:\n",
    "            map.append(idx)\n",
    "        else:\n",
    "            map.append(-1)\n",
    "    \n",
    "    print(f\"Mapped {len([i for i in map if i != -1])}/{len(canonical_vertices)} vertices successfully.\")\n",
    "\n",
    "    # remap face vertices\n",
    "    if len([i for i in map if i != -1])==len(canonical_vertices):\n",
    "        faces = data['_faces'].cpu().numpy()\n",
    "        for i,face in enumerate(faces):\n",
    "            x,y,z = face\n",
    "            data['_faces'][i][0] = map[x]\n",
    "            data['_faces'][i][1] = map[y]\n",
    "            data['_faces'][i][2] = map[z]\n",
    "            pass\n",
    "            \n",
    "        return data\n",
    "            \n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data import pass_smplx_dict\n",
    "\n",
    "def CheckAgainstSMPLX(smplx_path, params_dict, output):\n",
    "    model_params = dict(model_path=smplx_path,\n",
    "                            model_type='smplx',\n",
    "                            gender='Male',\n",
    "                            use_pca=True,\n",
    "                            use_hands=True,\n",
    "                            use_face=True,\n",
    "                            num_pca_comps=12,\n",
    "                            use_face_contour=False,\n",
    "                            create_global_orient=False,\n",
    "                            create_body_pose=False,\n",
    "                            create_betas=False,\n",
    "                            create_left_hand_pose=False,\n",
    "                            create_right_hand_pose=False,\n",
    "                            create_expression=False,\n",
    "                            create_jaw_pose=False,\n",
    "                            create_leye_pose=False,\n",
    "                            create_reye_pose=False,\n",
    "                            create_transl=False,\n",
    "                            flat_hand_mean=False,\n",
    "                            dtype=torch.float32,\n",
    "                            )\n",
    "\n",
    "\n",
    "    smplx_model = smplx.create(**model_params).cuda()\n",
    "    # model_output = pass_smplx_dict(params_dict, smplx_model, \"cuda\")\n",
    "    smplx_output = smplx_model(**params_dict)\n",
    "    # canonical_vertices = model_output['vertices'].detach().cpu().numpy().squeeze()\n",
    "    canonical_vertices = smplx_output.vertices.detach().cpu().numpy().squeeze()\n",
    "\n",
    "    tolerance = 5e-5\n",
    "    map = []\n",
    "    u = output['vertices'].squeeze().detach().cpu().numpy()\n",
    "    # create mapping of canonical\n",
    "    for i, canon_v in enumerate(canonical_vertices):\n",
    "        # canon_v[0] *= -1\n",
    "        # print(f'({i},{canon_v})')\n",
    "        # Calculate distances between the current canonical vertex and all Unity vertices\n",
    "        distances = np.linalg.norm(u - canon_v, axis=1)\n",
    "        \n",
    "        # Find the closest Unity vertex\n",
    "        idx = np.argmin(distances)\n",
    "        \n",
    "        \n",
    "        # Check if the closest vertex is within the tolerance\n",
    "        if distances[idx] < tolerance:\n",
    "            map.append(idx)\n",
    "        else:\n",
    "            map.append(-1)\n",
    "    \n",
    "    print(f\"Mapped {len([i for i in map if i != -1])}/{len(canonical_vertices)} vertices successfully.\")\n",
    "\n",
    "    # # remap face vertices\n",
    "    # if len([i for i in map if i != -1])==len(canonical_vertices):\n",
    "    #     faces = data['_faces'].cpu().numpy()\n",
    "    #     for i,face in enumerate(faces):\n",
    "    #         x,y,z = face\n",
    "    #         data['_faces'][i][0] = map[x]\n",
    "    #         data['_faces'][i][1] = map[y]\n",
    "    #         data['_faces'][i][2] = map[z]\n",
    "    #         pass\n",
    "            \n",
    "    #     return data\n",
    "            \n",
    "    # else:\n",
    "    #     return None\n",
    "        \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.load_checkpoint(opt.pretrained)\n",
    "test_dataset, test_dataloader = create_test_datasets(config)\n",
    "it = iter(test_dataloader)\n",
    "batch = next(it)\n",
    "smplx_params = {}\n",
    "for k,v in batch['smplx_params'].items():\n",
    "    smplx_params[k] = v[1,...].cuda()\n",
    "smplx_params[\"betas\"] = runner._betas\n",
    "output = runner.predict_smplx_vertices(batch, calc_gaussians=True)\n",
    "\n",
    "for key in output.keys():\n",
    "    output[key] = output[key][1,:,:].cuda()\n",
    "smplx_path = '/mounted/home/dresden/repositories/HAHA/data'\n",
    "# CheckAgainstSMPLX(smplx_path,smplx_params,output)\n",
    "print('smplx_params...')\n",
    "for k in smplx_params:\n",
    "    print(f'k: {k}, shape: {smplx_params[k].shape}')\n",
    "print('output...')\n",
    "for k in output:\n",
    "    print(f'k: {k}, shape: {output[k].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "smplx_path = '/mounted/home/dresden/repositories/HAHA/data'\n",
    "smplx_model = smplx.create(smplx_path, model_type='smplx', gender='male', flat_hand_mean=True)\n",
    "output = smplx_model(return_full_pose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in output.items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output['full_pose'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CheckAgainstSMPLX(smplx_path,smplx_params,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in output.keys():\n",
    "    print(k)\n",
    "# runner.save_ply('./male3-test.ply',\n",
    "#                 output['gaussians_xyz'],\n",
    "#                 output['gaussians_colors'],\n",
    "#                 output['gaussians_opacity'],\n",
    "#                 output['gaussians_scales'],\n",
    "#                 output['gaussians_rotations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for k,v in smplx_params.items():\n",
    "    data[k] = v\n",
    "data['vertices'] = output['vertices']\n",
    "data['offset_xyz'] = output['offset_xyz']\n",
    "data['xyz'] = output['gaussians_xyz']\n",
    "data['rot'] = output['gaussians_rotations']\n",
    "data['scale'] = output['gaussians_scales']\n",
    "data['color'] = output['gaussians_colors']\n",
    "data['opacity'] = output['gaussians_opacity']\n",
    "del data['camera_matrix']\n",
    "del data['camera_transform']\n",
    "for k in data.keys():\n",
    "    print(f'k: {k}, shape: {data[k].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remap faces\n",
    "print(data['_faces'])\n",
    "test = RemapToUnity('/mounted/home/dresden/repositories/HAHA/data',\n",
    "             '/mounted/home/dresden/repositories/HAHA/ExportedVertices.json',\n",
    "             data)\n",
    "print(test['_faces'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['_faces'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,value in data.items():\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        data[key] = value.cpu().tolist()\n",
    "\n",
    "with open(\"sample_output_dict.json\",'w') as f:\n",
    "    json.dump(data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "smplx_model = smplx.create('/mounted/home/dresden/repositories/HAHA/data', model_type='smplx', gender='female', flat_hand_mean=True)\n",
    "output = smplx_model(return_full_pose=True)\n",
    "verts = output.vertices\n",
    "canonical_vertices = verts.detach().cpu().numpy().squeeze().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smplx_model = smplx.create('/mounted/home/dresden/repositories/HAHA/data', model_type='smplx', gender='female', flat_hand_mean=True)\n",
    "output = smplx_model(return_full_pose=True)\n",
    "for k in output.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"smplxVerts.json\",'w') as f:\n",
    "    json.dump(canonical_vertices,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['_faces'][0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verts = verts.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceVerts = data['_faces'].long()\n",
    "sampled = verts[faceVerts]\n",
    "vec1 = sampled[:, 2] - sampled[:, 1]\n",
    "vec2 = sampled[:, 0] - sampled[:, 1]\n",
    "vec3 = sampled[:, 0] - sampled[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled[:, 2][0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating the modified state_dict used in unity\n",
    "\n",
    "with open('updated_dict.json','r') as f:\n",
    "    data = json.load(f)\n",
    "    data['_faces'] = torch.tensor(data['_faces'], dtype=torch.int32)\n",
    "\n",
    "print(data['_faces'])\n",
    "result = RemapToUnity('/mounted/home/dresden/repositories/HAHA/data',\n",
    "             '/mounted/home/dresden/repositories/HAHA/ExportedVertices.json',\n",
    "             data)\n",
    "print(result['_faces'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = np.load('/mounted/home/dresden/repositories/HAHA/data/smplx/SMPLX_FEMALE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(smplx_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute centroids for a set of faces and vertices\n",
    "def compute_centroids(vertices, faces):\n",
    "    centroids = []\n",
    "    for face in faces:\n",
    "        # Get the vertices of the face\n",
    "        v0, v1, v2 = vertices[face[0]], vertices[face[1]], vertices[face[2]]\n",
    "        centroid = (v0 + v1 + v2) / 3.0  # Compute centroid as the average of the vertices\n",
    "        centroids.append(centroid)\n",
    "    return np.array(centroids)\n",
    "# Compute centroids for SMPL-X and Unity faces\n",
    "smplx_centroids = compute_centroids(smplx_vertices, smplx_faces)\n",
    "unity_centroids = compute_centroids(unity_vertices, unity_faces)\n",
    "# Function to remap SMPL-X faces based on normals and centroids\n",
    "def remap_faces_refined(smplx_normals, smplx_centroids, smplx_faces, unity_normals, unity_centroids, unity_faces, w_normal=1.0, w_centroid=1.0):\n",
    "    remapped_faces = []\n",
    "    for smplx_normal, smplx_centroid, smplx_face in zip(smplx_normals, smplx_centroids, smplx_faces):\n",
    "        # Compute the difference in normals and centroids\n",
    "        normal_differences = np.linalg.norm(unity_normals - smplx_normal, axis=1)\n",
    "        centroid_differences = np.linalg.norm(unity_centroids - smplx_centroid, axis=1)\n",
    "        # Weighted distance metric\n",
    "        distances = w_normal * normal_differences + w_centroid * centroid_differences\n",
    "        # Find the Unity face with the smallest weighted distance\n",
    "        closest_idx = np.argmin(distances)\n",
    "        remapped_faces.append(unity_faces[closest_idx])\n",
    "    return np.array(remapped_faces)\n",
    "# Perform the refined remapping\n",
    "remapped_faces_refined = remap_faces_refined(\n",
    "    smplx_normals, smplx_centroids, smplx_faces, unity_normals, unity_centroids, unity_faces, w_normal=1.0, w_centroid=1.0\n",
    ")\n",
    "# Save the refined remapped faces to a file\n",
    "remapped_faces_refined_path = 'RefinedRemappedUnityFaces.txt'\n",
    "np.savetxt(remapped_faces_refined_path, remapped_faces_refined, fmt='%d', delimiter=',')\n",
    "remapped_faces_refined_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pid\n",
    "- smplx_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLogger:\n",
    "    def __init__(self, tpath, apath, cpath):\n",
    "        self.T = self.load_pose(tpath)\n",
    "        self.A = self.load_pose(apath)\n",
    "        self.C = self.load_pose(cpath)\n",
    "\n",
    "    def load_pose(self,path):\n",
    "        camera_matrix = torch.tensor([[[4.9270 * 3, 0.0000, -0.0519, 0.0000],\n",
    "                                       [0.0000, 4.9415 * 3, 0.0000, 0.0000],\n",
    "                                       [0.0000, 0.0000, 1.0001, -0.0101],\n",
    "                                       [0.0000, 0.0000, 1.0000, 0.0000]]], device='cuda')\n",
    "        camera_transform = torch.tensor([[[1., 0., 0., 0.],\n",
    "                                          [0., 1., 0., 0.9],\n",
    "                                          [0., 0., 1., 15.2122],\n",
    "                                          [0., 0., 0., 1.]]], device=\"cuda\")\n",
    "\n",
    "        with open(path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        smplx_params = {}\n",
    "        smplx_params[\"transl\"] = torch.FloatTensor(data[\"transl\"]).unsqueeze(0).unsqueeze(0)\n",
    "        smplx_params[\"global_orient\"] = torch.FloatTensor(data[\"global_orient\"]).unsqueeze(0).unsqueeze(0)\n",
    "        smplx_params[\"body_pose\"] = torch.FloatTensor(data[\"body_pose\"]).unsqueeze(0).unsqueeze(0)\n",
    "        smplx_params[\"right_hand_pose\"] = torch.FloatTensor(data[\"right_hand_pose\"]).unsqueeze(0).unsqueeze(0)\n",
    "        smplx_params[\"left_hand_pose\"] = torch.FloatTensor(data[\"left_hand_pose\"]).unsqueeze(0).unsqueeze(0)\n",
    "        smplx_params[\"leye_pose\"] = torch.FloatTensor(data[\"leye_pose\"]).unsqueeze(0).unsqueeze(0)\n",
    "        smplx_params[\"reye_pose\"] = torch.FloatTensor(data[\"reye_pose\"]).unsqueeze(0).unsqueeze(0)\n",
    "        smplx_params[\"jaw_pose\"] = torch.FloatTensor(data[\"jaw_pose\"]).unsqueeze(0).unsqueeze(0)\n",
    "        smplx_params[\"expression\"] = torch.FloatTensor(data[\"expression\"]).unsqueeze(0).unsqueeze(0)\n",
    "        smplx_params[\"betas\"] = torch.FloatTensor(data[\"betas\"]).unsqueeze(0).unsqueeze(0)\n",
    "        smplx_params[\"camera_matrix\"] = camera_matrix.unsqueeze(0)\n",
    "        smplx_params[\"camera_transform\"] = camera_transform.unsqueeze(0)\n",
    "\n",
    "        return smplx_params\n",
    "\n",
    "        \n",
    "\n",
    "    def _log_data_val(self, save_folder, batch, global_step):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def on_train_batch_end(\n",
    "            self,\n",
    "            runner,\n",
    "            outputs\n",
    "    ):\n",
    "        pass\n",
    "\n",
    "    def on_validation_batch_end(\n",
    "            self,\n",
    "            runner,\n",
    "            outputs\n",
    "    ):\n",
    "        # save_folder = os.path.join(runner.logger.log_dir, 'val')\n",
    "        # self._log_data_val(save_folder, outputs, runner.global_step)\n",
    "        pass\n",
    "\n",
    "    def on_test_batch_end(\n",
    "            self,\n",
    "            runner,\n",
    "            outputs\n",
    "    ):\n",
    "        pass\n",
    "\n",
    "    def on_test_end(self, runner):\n",
    "        save_folder = os.path.join(runner.logger.log_dir, 'data')\n",
    "        data_dict = {}\n",
    "        data_dict[\"pid\"] = [\"000\"]\n",
    "        name = [\"T\", \"A\", \"C\"]\n",
    "\n",
    "        for name,smplx_params in zip(name,[self.T, self.A, self.C]):\n",
    "\n",
    "            smplx_params[\"transl\"] = smplx_params[\"transl\"].to(runner.device)\n",
    "            smplx_params[\"global_orient\"] = smplx_params[\"global_orient\"].to(runner.device)\n",
    "            smplx_params[\"body_pose\"] = smplx_params[\"body_pose\"].to(runner.device)\n",
    "            smplx_params[\"right_hand_pose\"] = smplx_params[\"right_hand_pose\"].to(runner.device)\n",
    "            smplx_params[\"left_hand_pose\"] = smplx_params[\"left_hand_pose\"].to(runner.device)\n",
    "\n",
    "            data_dict[\"smplx_params\"] = smplx_params\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output = runner.predict_smplx_vertices(data_dict, calc_gaussians=True)\n",
    "            \n",
    "            for key in output.keys():\n",
    "                output[key] = output[key][0,...]\n",
    "            \n",
    "            runner.save_ply(os.path.join(save_folder, f'output_{name}.ply'),\n",
    "                            output['gaussians_xyz'],\n",
    "                            output['gaussians_colors'],\n",
    "                            output['gaussians_opacity'],\n",
    "                            output['gaussians_scales'],\n",
    "                            output['gaussians_rotations'])\n",
    "            \n",
    "            for key,value in output.items():\n",
    "                if isinstance(value, torch.Tensor):\n",
    "                    output[key] = value.cpu().tolist()\n",
    "            with open(os.path.join(save_folder, f'output_{name}.json','w')) as f:\n",
    "                json.dump(output,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpath = '/mounted/home/dresden/repositories/HAHA/T.json'\n",
    "apath = '/mounted/home/dresden/repositories/HAHA/A.json'\n",
    "cpath = '/mounted/home/dresden/repositories/HAHA/C.json'\n",
    "d = DataLogger(tpath,apath,cpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.T[\"transl\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 13541, 3])\n",
      "torch.Size([1, 13541, 4])\n",
      "torch.Size([1, 13541, 1])\n",
      "torch.Size([1, 13541, 3])\n",
      "torch.Size([1, 13541, 3])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_test_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36mDataLogger.on_test_end\u001b[0;34m(self, runner)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     82\u001b[0m     output \u001b[38;5;241m=\u001b[39m runner\u001b[38;5;241m.\u001b[39mpredict_smplx_vertices(data_dict, calc_gaussians\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 84\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241m.\u001b[39msave_ply(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.ply\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     85\u001b[0m                 output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgaussians_xyz\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     86\u001b[0m                 output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgaussians_colors\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     87\u001b[0m                 output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgaussians_opacity\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     88\u001b[0m                 output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgaussians_scales\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     89\u001b[0m                 output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgaussians_rotations\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key,value \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36mDataLogger.on_test_end\u001b[0;34m(self, runner)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     82\u001b[0m     output \u001b[38;5;241m=\u001b[39m runner\u001b[38;5;241m.\u001b[39mpredict_smplx_vertices(data_dict, calc_gaussians\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 84\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241m.\u001b[39msave_ply(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.ply\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     85\u001b[0m                 output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgaussians_xyz\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     86\u001b[0m                 output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgaussians_colors\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     87\u001b[0m                 output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgaussians_opacity\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     88\u001b[0m                 output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgaussians_scales\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     89\u001b[0m                 output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgaussians_rotations\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key,value \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda/envs/textured-avatar/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/textured-avatar/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "d.on_test_end(runner)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
